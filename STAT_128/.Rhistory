data = penguins,
mapping = aes(x = island, y = body_mass_g)
) +
geom_boxplot() +
labs (
x = "island", y = "body mass (g)"
)
ggplot(
data = diamonds,
mapping = aes(x = carat)
) +
geom_histogram(binwidth = 0.03)
ggplot(
data = diamonds,
mapping = aes(x = carat, y = price)
) +
geom_point(aes(color = cut)) +
labs(
title = "Diamond values",
x = "Carat", y = "Price in US Dollars",
color = "Cut"
)
ggplot(
data = mpg,
mapping = aes(x = displ, y = hwy)
) +
geom_point(aes(color = cyl, size = cyl))
ggplot(
data = mpg,
mapping = aes(x = displ, y = hwy, linewidth = 0.75)
) +
geom_point(aes(color = cyl))
library(tidyverse)
library(nycflights13)
library(tidyverse)
ggplot(
data = mpg,
mapping = aes(x = displ, y = hwy)
) +
geom_point() +
geom_smooth(method = "lm")
flights |> filter(arr_delay >= 120)
flights |> filter(dest == "IAH" | dest == "HOU")
flights |> filter(carrier == "UA" | carrier == "AA" | carrier == "DL")
flights |> filter(month == 7 | month == 8 | month == 9)
flights |> filter(arr_delay > 120 & dep_delay < 0)
flights |> filter (dep_delay >= 60 & air_time > 30)
# ????? I'm not entirely sure what this question is asking
flights |> filter(dep_time < 1200) |> arrange(desc(dep_delay), dep_time)
# flights with the longest departure delays
arrange(flights, desc(dep_delay))
# flights that left earliest in the morning (displays all flights from morning until afternoon)
filter(flights, dep_time < 1200) |>
arrange(dep_time)
mutate(flights, speed = distance / (air_time / 60), .before = 1) |>
arrange(desc(speed))
flights |>
group_by(month, day) |>
summarize(count = n())
# flights that traveled the least distance
select(flights, year:day, carrier, flight, air_time, distance) |>
arrange(distance, air_time)
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_min(distance, n = 1)
# flights that traveled the farthest distance
select(flights, year:day, carrier, flight, air_time, distance) |>
arrange(desc(distance), desc(air_time))
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_max(distance, n = 1) |>
arrange(desc(air_time))
# experiment
select(flights, year, year, year)
select(flights, year, year, day, day)
select(flights, year, day, year, day)
rename(flights, air_time_min = air_time) |>
relocate(air_time_min, .before = 1)
# I'm also confused with how to approach this, but I'll try my best:
# carriers with the longest avg total delay
group_by(flights, carrier) |>
summarize(avg_dep_delay = (dep_delay, na.rm = TRUE),
library(tidyverse)
library(nycflights13)
library(tidyverse)
ggplot(
data = mpg,
mapping = aes(x = displ, y = hwy)
) +
geom_point() +
geom_smooth(method = "lm")
flights |> filter(arr_delay >= 120)
flights |> filter(dest == "IAH" | dest == "HOU")
flights |> filter(carrier == "UA" | carrier == "AA" | carrier == "DL")
flights |> filter(month == 7 | month == 8 | month == 9)
flights |> filter(arr_delay > 120 & dep_delay < 0)
flights |> filter (dep_delay >= 60 & air_time > 30)
# ????? I'm not entirely sure what this question is asking
flights |> filter(dep_time < 1200) |> arrange(desc(dep_delay), dep_time)
# flights with the longest departure delays
arrange(flights, desc(dep_delay))
# flights that left earliest in the morning (displays all flights from morning until afternoon)
filter(flights, dep_time < 1200) |>
arrange(dep_time)
mutate(flights, speed = distance / (air_time / 60), .before = 1) |>
arrange(desc(speed))
flights |>
group_by(month, day) |>
summarize(count = n())
# flights that traveled the least distance
select(flights, year:day, carrier, flight, air_time, distance) |>
arrange(distance, air_time)
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_min(distance, n = 1)
# flights that traveled the farthest distance
select(flights, year:day, carrier, flight, air_time, distance) |>
arrange(desc(distance), desc(air_time))
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_max(distance, n = 1) |>
arrange(desc(air_time))
# experiment
select(flights, year, year, year)
select(flights, year, year, day, day)
select(flights, year, day, year, day)
rename(flights, air_time_min = air_time) |>
relocate(air_time_min, .before = 1)
# I'm also confused with how to approach this, but I'll try my best:
# carriers with the longest avg total delay
group_by(flights, carrier) |>
summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE),
avg_arr_delay = mean(arr_delay, na.rm = TRUE)) |>
mutate(avg_total_delay = (avg_dep_delay + avg_arr_delay) / 2) |>
arrange(desc(avg_total_delay))
# destination airports with the longest avg total delay
group_by(flights, dest) |>
summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE),
avg_arr_delay = mean(arr_delay, na.rm = TRUE)) |>
mutate(avg_total_delay = (avg_dep_delay + avg_arr_delay) / 2) |>
arrange(desc(avg_total_delay))
# carriers, grouped by destination, with the longest avg total delay
group_by(flights, carrier, dest) |>
summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE),
avg_arr_delay = mean(arr_delay, na.rm = TRUE)) |>
mutate(avg_total_delay = (avg_dep_delay + avg_arr_delay) / 2) |>
arrange(desc(avg_total_delay))
group_by(flights, dest) |>
slice_max(dep_delay, n = 1) |>
relocate(dest, dep_delay)
# average length (in minutes) of departure delay per hour of the day
group_by(flights, hour) |>
summarize(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |>
ggplot(
mapping = aes(x = hour, y = avg_dep_delay)
) +
geom_line() +
labs(
x = "Hour of Day", y = "Average Departure Delay (min)"
)
# number of flights that are delayed over the course of the day
group_by(flights, hour) |>
filter(dep_delay > 0) |>
summarize(count = n()) |>
ggplot(
mapping = aes(x = hour, y = count)
) +
geom_line() +
labs(
x = "Hour of Day", y = "Number of Flights Delayed"
)
select(flights, year:day, carrier, flight, air_time, distance)
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_head(n = 5)
select(flights, year:day, carrier, flight, air_time, distance) |>
slice_head(n = -5)
# finding the days of each month with the highest number of flights
group_by(flights, month, day) |>
summarize(count = n()) |>
slice_max(count) |>
arrange(desc(count))
# if we take the day with the most departures, we can find the
# busiest time to catch a flight out of NYC in 2013
filter(flights, month == 11, day == 27) |>
group_by(hour) |>
summarize(count = n()) |>
arrange(desc(count))
# plotting the data:
filter(flights, month == 11, day == 27) |>
group_by(hour) |>
summarize(count = n()) |>
arrange(desc(count)) |>
ggplot(
mapping = aes(x = hour, y = count)
) +
geom_line()
library(tidyverse)
# code to tidy data
water <- read_delim("/Users/Jessica/Downloads/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
rename(water_temp = `15722_00010`) |>
mutate(water_temp = as.double(water_temp),
datetime = ymd_hm(datetime, tz = "US/Pacific"))
library(tidyverse)
# code to tidy data
water <- read_delim("/Users/Jessica/Downloads/STAT_128/HW4_DataSets/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
rename(water_temp = `15722_00010`) |>
mutate(water_temp = as.double(water_temp),
datetime = ymd_hm(datetime, tz = "US/Pacific"))
water
slice(water, 1)
range(water$datetime)
water <- read_delim("/Users/Jessica/Downloads/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
rename(temperature = `15722_00010`, qual = `15722_00010_cd`) |>
select(datetime, temperature, qual) |>
mutate(temperature = as.double(temperature),
datetime = ymd_hm(datetime, tz = "US/Pacific"))
library(tidyverse)
# code to tidy data
water <- read_delim("/Users/Jessica/Downloads/STAT_128/HW4_DataSets/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
rename(water_temp = `15722_00010`) |>
mutate(water_temp = as.double(water_temp),
datetime = ymd_hm(datetime, tz = "US/Pacific"))
water
slice(water, 1)
range(water$datetime)
water <- read_delim("/Users/Jessica/Downloads/STAT_128/HW4_DataSets/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
rename(temperature = `15722_00010`, qual = `15722_00010_cd`) |>
select(datetime, temperature, qual) |>
mutate(temperature = as.double(temperature),
datetime = ymd_hm(datetime, tz = "US/Pacific"))
water
# time span the data covers
range(water$datetime)
# do we have all the days in between the start and end date?
water |>
group_by(date = ymd(datetime)) |>
summarize()
# do we have every time interval per day?
water |>
group_by(days = yday(datetime)) |>
summarize(count = n())
# completeness ratio
stack(colMeans(!is.na(water))*100)
# plotting the most recent full day of data
recent <- max(water$datetime)
water |>
filter(date(datetime) == date(recent) - 1) |>
ggplot(aes(x = datetime, y = temperature)) +
geom_line()
water |>
filter(date(datetime) == date(recent) - 1) |>
ggplot(aes(x = datetime, y = temperature)) +
geom_point() +
labs(x = "One Day", y = "Temperature in Celsius")
recentWeek <- week(recent)
water |>
filter(week(datetime) == recentWeek - 1, year(datetime) == year(recent)) |>
ggplot(aes(x = datetime, y = temperature)) +
geom_point() +
labs(x ="One Week", y = "Temperature in Celsius")
# find the averages of the temperature per day
mean <- water |>
group_by(date = date(datetime)) |>
summarize(avg_temp = mean(temperature))
# isolate the warmest and coldest days
range <- range(mean$avg_temp)
warmCool <- subset(mean, avg_temp %in% range)
# plot the average temps with annotations
mean |>
ggplot(aes(x = date, y = avg_temp)) +
geom_point(alpha = 0.4) +
geom_point(data = warmCool |> slice_max(avg_temp), color = "red") +
geom_point(data = warmCool |> slice_min(avg_temp), color = "blue") +
annotate("text", x = ymd("2023-02-24"), y = 6.7,
label = "Coldest Day", color = "blue", size = 2.5) +
annotate("text", x = ymd("2021-07-10"), y = 25.3,
label = "Warmest Day", color = "red", size = 2.5)
mean |>
ggplot(aes(x = date, y = avg_temp)) +
geom_point() +
labs(y = "Avg. Temp. in Celsius")
water |>
mutate(temperature_f = (temperature * 9)/5 + 32) |>
group_by(date = date(datetime)) |>
summarize(avg_temp = mean(temperature_f)) |>
ggplot(aes(x = date, y = avg_temp)) +
geom_point() +
geom_hline(yintercept = 60, color = "blue", size = 1) +
labs(y = "Avg. Temp. in Fahrenheit")
water |>
mutate(temperature_f = (temperature * 9)/5 + 32) |>
filter(temperature_f < 60) |>
group_by(month(datetime)) |>
summarize()
# finding the highest temperature in each year
water |>
group_by(year(datetime)) |>
summarize(max(temperature))
# finding the months in 2021 that have a higher temperature than the
# warmest day in 2023 (the year with the lowest high temperature)
water |>
filter(year(datetime) == 2021, temperature > 20.9) |>
group_by(month(datetime)) |>
summarize()
# plotting the warmest days in 2021
water |>
filter(year(datetime) == 2021, temperature > 20.9) |>
group_by(date = ymd(datetime)) |>
summarize(avg_temp_cel = mean(temperature)) |>
ggplot(aes(x = date, y = avg_temp_cel)) +
geom_point() +
geom_smooth()
library(tidyverse)
w <- readRDS("/Users/Jessica/Downloads/STAT_128/HW5_Interpolation/sep2023.rds")
# range of entire data set
range(w$time)
# finding the days that have missing data
w |>
group_by(day(time)) |>
summarize(n())
# finding the times that are missing
allTimes <- seq(from = min(w$time), to = max(w$time), by = "15 min")
missingTimes <- as.POSIXct(setdiff(allTimes, w$time), tz = "UTC")
# range of missing data points
range(missingTimes)
# sanity check
table <- tibble(missingTimes)
table |>
group_by(day(missingTimes)) |>
summarize(n())
missing <- tibble(time = missingTimes)
w2 <- filter(w, day(time) > 17 & day(time) < 22)
mul <- 2*pi/24
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
w2_pred <- bind_rows(w2, missing)
w2_pred$temperature <- predict(model, w2_pred)
coef(model)
missing$status <- "estimated"
w2$status <- "observed"
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
missing$temperature <- predict(model, missing)
w2 <- bind_rows(w2, missing)
ggplot(w2, aes(x = time, y = temperature)) +
geom_point(aes(color = status)) +
theme_minimal() +
geom_line(data = w2_pred)
water <- read_delim("/Users/Jessica/Downloads/water-temp.txt", comment="#", delim="\t") |>
slice(-1) |>
filter(day(datetime) > 17 & day(datetime) < 22 &
year(datetime) == 2023 & month(datetime) == 9) |>
rename(temperature = `15722_00010`, qual = `15722_00010_cd`) |>
select(datetime, temperature, qual) |>
mutate(temperature = as.double(temperature),
datetime = ymd_hm(datetime, tz = "US/Pacific"),
temperature_f = (temperature * 9)/5 + 32)
library(tidyverse)
w <- readRDS("/Users/Jessica/Downloads/STAT_128/HW5_Interpolation/sep2023.rds")
# range of entire data set
range(w$time)
# finding the days that have missing data
w |>
group_by(day(time)) |>
summarize(n())
# finding the times that are missing
allTimes <- seq(from = min(w$time), to = max(w$time), by = "15 min")
missingTimes <- as.POSIXct(setdiff(allTimes, w$time), tz = "UTC")
# range of missing data points
range(missingTimes)
# sanity check
table <- tibble(missingTimes)
table |>
group_by(day(missingTimes)) |>
summarize(n())
missing <- tibble(time = missingTimes)
w2 <- filter(w, day(time) > 17 & day(time) < 22)
mul <- 2*pi/24
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
w2_pred <- bind_rows(w2, missing)
w2_pred$temperature <- predict(model, w2_pred)
coef(model)
missing$status <- "estimated"
w2$status <- "observed"
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
missing$temperature <- predict(model, missing)
w2 <- bind_rows(w2, missing)
ggplot(w2, aes(x = time, y = temperature)) +
geom_point(aes(color = status)) +
theme_minimal() +
geom_line(data = w2_pred)
water <- read_delim("√/Users/Jessica/Downloads/STAT_128/HW4_DataSets/water-temp.txt",
comment="#", delim="\t") |>
slice(-1) |>
filter(day(datetime) > 17 & day(datetime) < 22 &
year(datetime) == 2023 & month(datetime) == 9) |>
rename(temperature = `15722_00010`, qual = `15722_00010_cd`) |>
select(datetime, temperature, qual) |>
mutate(temperature = as.double(temperature),
datetime = ymd_hm(datetime, tz = "US/Pacific"),
temperature_f = (temperature * 9)/5 + 32)
library(tidyverse)
w <- readRDS("/Users/Jessica/Downloads/STAT_128/HW5_Interpolation/sep2023.rds")
# range of entire data set
range(w$time)
# finding the days that have missing data
w |>
group_by(day(time)) |>
summarize(n())
# finding the times that are missing
allTimes <- seq(from = min(w$time), to = max(w$time), by = "15 min")
missingTimes <- as.POSIXct(setdiff(allTimes, w$time), tz = "UTC")
# range of missing data points
range(missingTimes)
# sanity check
table <- tibble(missingTimes)
table |>
group_by(day(missingTimes)) |>
summarize(n())
missing <- tibble(time = missingTimes)
w2 <- filter(w, day(time) > 17 & day(time) < 22)
mul <- 2*pi/24
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
w2_pred <- bind_rows(w2, missing)
w2_pred$temperature <- predict(model, w2_pred)
coef(model)
missing$status <- "estimated"
w2$status <- "observed"
model <- lm(temperature ~ sin(mul * (hour(time) + minute(time)/60)), w2)
missing$temperature <- predict(model, missing)
w2 <- bind_rows(w2, missing)
ggplot(w2, aes(x = time, y = temperature)) +
geom_point(aes(color = status)) +
theme_minimal() +
geom_line(data = w2_pred)
water <- read_delim("/Users/Jessica/Downloads/STAT_128/HW4_DataSets/water-temp.txt",
comment="#", delim="\t") |>
slice(-1) |>
filter(day(datetime) > 17 & day(datetime) < 22 &
year(datetime) == 2023 & month(datetime) == 9) |>
rename(temperature = `15722_00010`, qual = `15722_00010_cd`) |>
select(datetime, temperature, qual) |>
mutate(temperature = as.double(temperature),
datetime = ymd_hm(datetime, tz = "US/Pacific"),
temperature_f = (temperature * 9)/5 + 32)
ggplot(water, aes(x = datetime, y = temperature_f)) +
geom_point(color = "red") +
geom_line(data = w2_pred, aes(x = time, y = temperature), color = "blue") +
labs(subtitle = "Model predictions in blue")
pts <- c(2, 3, 4, 5, 3, 3, 4, 3, 2)
paste("total points possible:", sum(pts))
library(tidyverse)
law <- function(x) {
prob = log10(1 + 1/x)
prob
}
law(2)
law(7)
law(2)/law(7)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
pts <- c(2, 3, 4, 5, 3, 3, 4, 3, 2)
paste("total points possible:", sum(pts))
library(tidyverse)
law <- function(x) {
prob = log10(1 + 1/x)
prob
}
law(2)
law(7)
law(2)/law(7)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
library(tidyverse)
pts <- c(2, 3, 4, 5, 3, 3, 4, 3, 2)
paste("total points possible:", sum(pts))
library(tidyverse)
pts <- c(2, 3, 4, 5, 3, 3, 4, 3, 2)
paste("total points possible:", sum(pts))
library(tidyverse)
law <- function(x) {
prob = log10(1 + 1/x)
prob
}
law(2)
law(7)
law(2)/law(7)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
digits <- c(1:9)
digits <- c(1:9)
benford <- data.frame(
digits = c(1:9),
results = law(digits)
)
ggplot(benford, mapping = aes(x = digits, y = results)) +
geom_point() +
labs(y = "P(d)") +
scale_x_continuous(breaks = seq(1, 9, by=1))
